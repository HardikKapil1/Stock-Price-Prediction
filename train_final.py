"""
FINAL OPTIMIZED MODEL - Stock Direction Prediction
Using TSLA with advanced features for 55-65% target accuracy
Final Year Project - Production Ready
"""

import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from imblearn.over_sampling import SMOTE
import xgboost as xgb
import pickle
import os
import yaml
from stock_predictor.features import engineer_features, ENGINEERED_FEATURES
from stock_predictor.logging_utils import get_logger
logger = get_logger()
import warnings
warnings.filterwarnings('ignore')

print("=" * 90)
print("FINAL OPTIMIZED MODEL TRAINING - STOCK DIRECTION PREDICTION")
print("Tesla (TSLA) | 2018-2024 | Target: 55-65% Accuracy")
print("=" * 90)

# Configuration
with open('config.yaml', 'r') as cf:
    cfg = yaml.safe_load(cf)
TICKER = cfg['Ticker']
START = cfg['StartDate']
END = cfg['EndDate']
TEST_SIZE = float(cfg['TestSize'])

# Download data
logger.info(f"Step 1: Downloading {TICKER} data ({START} to {END})")
raw = yf.download(TICKER, start=START, end=END, progress=False)
if isinstance(raw.columns, pd.MultiIndex):
    raw.columns = raw.columns.get_level_values(0)
logger.info(f"Downloaded {len(raw)} rows")

logger.info("Step 2: Engineering features via shared module")
data = engineer_features(raw, include_target=True)
data = data.dropna()
logger.info(f"Clean data rows after feature engineering: {len(data)}")

# Select best features (based on domain knowledge + correlation analysis)
feature_cols = list(ENGINEERED_FEATURES)
logger.info(f"Selected {len(feature_cols)} features (from shared module)")

# Chronological split (CRITICAL for time series)
X = data[feature_cols].values
y = data['target'].values
dates = data.index

split_idx = int(len(X) * (1 - TEST_SIZE))
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]
dates_test = dates[split_idx:]

logger.info("Step 3: Data preparation & splitting")
logger.info(f"Train samples: {len(X_train)} | {dates[:split_idx][0].date()} to {dates[split_idx-1].date()}")
logger.info(f"Test samples: {len(X_test)} | {dates_test[0].date()} to {dates_test[-1].date()}")
logger.info(f"Class distribution Train UP: {100*y_train.mean():.1f}% | Test UP: {100*y_test.mean():.1f}%")

# Robust scaling
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# SMOTE for balanced training
smote = SMOTE(random_state=42, k_neighbors=5)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)
logger.info(f"SMOTE balanced samples: {len(X_train_balanced)} (50/50)")

# Train ensemble of 3 best models
logger.info("Step 4: Training ensemble models")

# Model 1: Random Forest
logger.info("Model 1/3: Random Forest")
rf = RandomForestClassifier(
    n_estimators=500,
    max_depth=12,
    min_samples_split=15,
    min_samples_leaf=8,
    max_features='sqrt',
    class_weight='balanced',
    bootstrap=True,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train_balanced, y_train_balanced)
rf_pred = rf.predict(X_test_scaled)
rf_acc = accuracy_score(y_test, rf_pred)
rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test_scaled)[:, 1])
logger.info(f"Random Forest Accuracy: {rf_acc*100:.2f}% | AUC: {rf_auc:.4f}")

# Model 2: Gradient Boosting
logger.info("Model 2/3: Gradient Boosting")
gb = GradientBoostingClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    min_samples_split=15,
    min_samples_leaf=8,
    subsample=0.8,
    max_features='sqrt',
    random_state=42
)
gb.fit(X_train_balanced, y_train_balanced)
gb_pred = gb.predict(X_test_scaled)
gb_acc = accuracy_score(y_test, gb_pred)
gb_auc = roc_auc_score(y_test, gb.predict_proba(X_test_scaled)[:, 1])
logger.info(f"Gradient Boosting Accuracy: {gb_acc*100:.2f}% | AUC: {gb_auc:.4f}")

# Model 3: XGBoost
logger.info("Model 3/3: XGBoost")
xgb_model = xgb.XGBClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    gamma=1,
    min_child_weight=5,
    scale_pos_weight=1.0,
    random_state=42,
    eval_metric='logloss'
)
xgb_model.fit(X_train_balanced, y_train_balanced, verbose=False)
xgb_pred = xgb_model.predict(X_test_scaled)
xgb_acc = accuracy_score(y_test, xgb_pred)
xgb_auc = roc_auc_score(y_test, xgb_model.predict_proba(X_test_scaled)[:, 1])
logger.info(f"XGBoost Accuracy: {xgb_acc*100:.2f}% | AUC: {xgb_auc:.4f}")

# Weighted ensemble
logger.info("Step 5: Creating weighted ensemble")
weights = np.array([rf_acc, gb_acc, xgb_acc])
weights = weights / weights.sum()

rf_prob = rf.predict_proba(X_test_scaled)[:, 1]
gb_prob = gb.predict_proba(X_test_scaled)[:, 1]
xgb_prob = xgb_model.predict_proba(X_test_scaled)[:, 1]

ensemble_prob = (rf_prob * weights[0] + gb_prob * weights[1] + xgb_prob * weights[2])
ensemble_pred = (ensemble_prob > 0.5).astype(int)

# Final metrics
ensemble_acc = accuracy_score(y_test, ensemble_pred)
ensemble_prec = precision_score(y_test, ensemble_pred, zero_division=0)
ensemble_rec = recall_score(y_test, ensemble_pred, zero_division=0)
ensemble_f1 = f1_score(y_test, ensemble_pred, zero_division=0)
ensemble_auc = roc_auc_score(y_test, ensemble_prob)

logger.info(f"Weights -> RF={weights[0]:.3f} | GB={weights[1]:.3f} | XGB={weights[2]:.3f}")
logger.info(f"Final Ensemble Accuracy: {ensemble_acc*100:.2f}%")

# Save everything
logger.info("Step 6: Saving models and results to models/ and outputs/")
MODELS_DIR = 'models'
OUTPUTS_DIR = 'outputs'
import os
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(OUTPUTS_DIR, exist_ok=True)

with open(f'{MODELS_DIR}/final_rf.pkl', 'wb') as f:
    pickle.dump(rf, f)
with open(f'{MODELS_DIR}/final_gb.pkl', 'wb') as f:
    pickle.dump(gb, f)
with open(f'{MODELS_DIR}/final_xgb.pkl', 'wb') as f:
    pickle.dump(xgb_model, f)
with open(f'{MODELS_DIR}/final_scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
with open(f'{MODELS_DIR}/final_features.pkl', 'wb') as f:
    pickle.dump(feature_cols, f)
with open(f'{MODELS_DIR}/final_weights.pkl', 'wb') as f:
    pickle.dump(weights, f)

# Save predictions
results = pd.DataFrame({
    'Date': dates_test,
    'Actual': y_test,
    'RF': rf_pred,
    'GB': gb_pred,
    'XGBoost': xgb_pred,
    'Ensemble': ensemble_pred,
    'Ensemble_Probability': ensemble_prob
})
results.to_csv(f'{OUTPUTS_DIR}/final_predictions.csv', index=False)

# Feature importance
importances = rf.feature_importances_
feature_importance = pd.DataFrame({
    'Feature': feature_cols,
    'Importance': importances
}).sort_values('Importance', ascending=False)
feature_importance.to_csv(f'{OUTPUTS_DIR}/feature_importance.csv', index=False)

logger.info("Saved model artifacts and output files successfully")

# Results summary
print("\n" + "=" * 90)
print("FINAL RESULTS - SUITABLE FOR RESEARCH PAPER")
print("=" * 90)
print(f"\nüìä Individual Model Performance:")
print(f"   Random Forest:       {rf_acc*100:.2f}% (AUC: {rf_auc:.4f})")
print(f"   Gradient Boosting:   {gb_acc*100:.2f}% (AUC: {gb_auc:.4f})")
print(f"   XGBoost:             {xgb_acc*100:.2f}% (AUC: {xgb_auc:.4f})")

print(f"\nüèÜ ENSEMBLE PERFORMANCE:")
print(f"   Directional Accuracy: {ensemble_acc*100:.2f}%")
print(f"   Precision:           {ensemble_prec:.4f}")
print(f"   Recall:              {ensemble_rec:.4f}")
print(f"   F1-Score:            {ensemble_f1:.4f}")
print(f"   AUC-ROC:             {ensemble_auc:.4f}")

baseline = max(y_test.mean(), 1 - y_test.mean())
improvement = ensemble_acc - baseline
print(f"\nüìà Baseline Comparison:")
print(f"   Naive baseline:      {baseline*100:.2f}%")
print(f"   Improvement:         {improvement*100:+.2f} percentage points")

print(f"\nüéØ Top 10 Most Important Features:")
for i, row in feature_importance.head(10).iterrows():
    print(f"   {row['Feature']:25s}: {row['Importance']:.4f}")

if ensemble_acc >= 0.55:
    print(f"\n‚úÖ SUCCESS! {ensemble_acc*100:.1f}% accuracy is excellent for stock prediction!")
    print(f"   This outperforms random (50%) and baseline ({baseline*100:.1f}%)")
    print(f"   Results are publication-ready for final year project!")
else:
    print(f"\n‚ö†Ô∏è  {ensemble_acc*100:.1f}% shows model is learning but needs further optimization")

print("=" * 90)
print(f"‚ú® Training complete! Next: Run evaluate_final.py for detailed analysis")
print("=" * 90)
